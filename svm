import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE
from sklearn.model_selection import StratifiedKFold
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

# read Excel
# df = pd.read_excel(r'E:\result\svm\data\sivsfsi\sivsfsi11.xlsx', engine='openpyxl', header=None)
df = pd.read_excel(r'E:\result\svm\data\sivsnc\mddvsnc12.xlsx', engine='openpyxl', header=None)


# 
X = df.iloc[:, :200].values  # 
y = df.iloc[:, 200].values   # 

# building svm model
svm_model = SVC(kernel="linear", probability=True)

# using StratifiedKFold to 5-fold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)

# 
results = []

# 
for n_features in range(20, 201, 20):
    print(f"Evaluating RFE with {n_features} features")
    
    # 
    rfe = RFE(estimator=svm_model, n_features_to_select=n_features)
    rfe.fit(X, y)

    # 
    selected_features = X[:, rfe.support_]

    # 
    accuracy_list = []
    precision_list = []
    recall_list = []
    f1_list = []

    for train_index, test_index in skf.split(selected_features, y):
        # 
        X_train, X_test = selected_features[train_index], selected_features[test_index]
        y_train, y_test = y[train_index], y[test_index]
        
        # 
        svm_model.fit(X_train, y_train)
        
        # 
        y_pred = svm_model.predict(X_test)
        
        # 
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='binary')
        recall = recall_score(y_test, y_pred, average='binary')
        f1 = f1_score(y_test, y_pred, average='binary')
        
        # 
        accuracy_list.append(accuracy)
        precision_list.append(precision)
        recall_list.append(recall)
        f1_list.append(f1)
    
    # 
    avg_accuracy = np.mean(accuracy_list)
    avg_precision = np.mean(precision_list)
    avg_recall = np.mean(recall_list)
    avg_f1 = np.mean(f1_list)
    
    std_accuracy = np.std(accuracy_list)
    std_precision = np.std(precision_list)
    std_recall = np.std(recall_list)
    std_f1 = np.std(f1_list)
    
    # 
    results.append({
        'n_features': n_features,
        'avg_accuracy': avg_accuracy,
        'std_accuracy': std_accuracy,
        'avg_precision': avg_precision,
        'std_precision': std_precision,
        'avg_recall': avg_recall,
        'std_recall': std_recall,
        'avg_f1': avg_f1,
        'std_f1': std_f1
    })

    # 
    print(f"Features: {n_features}, Avg Accuracy: {avg_accuracy:.4f} ± {std_accuracy:.4f}, "
          f"Avg Precision: {avg_precision:.4f} ± {std_precision:.4f}, "
          f"Avg Recall: {avg_recall:.4f} ± {std_recall:.4f}, Avg F1: {avg_f1:.4f} ± {std_f1:.4f}")

# 
results_df = pd.DataFrame(results)

# 
results_df.to_excel("rfe_feature_selection_results_with_std.xlsx", index=False)

# 
print("\nOptimal feature selection results:")
for result in results:
    print(f"Features: {result['n_features']}, Avg Accuracy: {result['avg_accuracy']:.4f} ± {result['std_accuracy']:.4f}, "
          f"Avg Precision: {result['avg_precision']:.4f} ± {result['std_precision']:.4f}, "
          f"Avg Recall: {result['avg_recall']:.4f} ± {result['std_recall']:.4f}, Avg F1: {result['avg_f1']:.4f} ± {result['std_f1']:.4f}")

# 
best_result = max(results, key=lambda x: x['avg_f1'])
print(f"\nBest number of features: {best_result['n_features']} with Avg F1: {best_result['avg_f1']:.4f} ± {best_result['std_f1']:.4f}")
